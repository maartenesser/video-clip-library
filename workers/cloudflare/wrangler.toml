# Wrangler configuration for Cloudflare Containers
name = "video-processing-pipeline"
main = "src/worker.ts"
compatibility_date = "2024-01-01"
compatibility_flags = ["nodejs_compat"]

# Container configuration (using Durable Objects)
# Using standard-4 instance: 4 vCPU, 12 GiB memory, 20 GB disk
# Memory budget: ~6GB processing (streaming buffer 100MB + FFmpeg 2-4GB + PySceneDetect 1GB)
# This provides 50% headroom for large video processing (500MB+)
[[containers]]
class_name = "VideoProcessor"
image = "./Dockerfile"
max_instances = 5
instance_type = "standard-4"

# Cloudflare Queues configuration for async video processing
# Queue-based architecture decouples job submission from processing
# Enables retry logic and removes timeout pressure from Worker
[[queues.producers]]
queue = "video-processing-jobs"
binding = "VIDEO_QUEUE"

[[queues.consumers]]
queue = "video-processing-jobs"
max_batch_size = 1
max_concurrency = 5
max_retries = 3
dead_letter_queue = "video-processing-dlq"

# Dead letter queue for failed jobs
[[queues.producers]]
queue = "video-processing-dlq"
binding = "VIDEO_DLQ"

# Durable Objects binding for the container
[[durable_objects.bindings]]
name = "VIDEO_PROCESSOR"
class_name = "VideoProcessor"

# Migrations for Durable Objects
[[migrations]]
tag = "v1"
new_sqlite_classes = ["VideoProcessor"]

# Environment variables (set via wrangler secret)
[vars]
ENVIRONMENT = "production"

# Observability configuration
[observability]
enabled = true
head_sampling_rate = 1

[observability.logs]
enabled = true
head_sampling_rate = 1
persist = true
invocation_logs = true

[observability.traces]
enabled = false
persist = true
head_sampling_rate = 1

# R2 bucket binding
[[r2_buckets]]
binding = "VIDEO_BUCKET"
bucket_name = "video-clips"

# Secrets (configured via `wrangler secret put`)
# - OPENAI_API_KEY
# - R2_ACCESS_KEY_ID
# - R2_SECRET_ACCESS_KEY
# - WEBHOOK_SECRET
# - SUPABASE_URL
# - SUPABASE_SERVICE_KEY
